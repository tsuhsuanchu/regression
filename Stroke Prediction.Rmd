# Stroke Dataset
Read the dataset
```{r}
df = read.csv("stroke.csv", na.strings = c("N/A"))
head(df)
```


Which variables has any missing data
```{r}
colSums(is.na(df))
```
Only bmi has some N/A values

```{r}
### Missing Values
#Distribution for BMI
boxplot(df$bmi,data=df, main="Distribution BMI",xlab="BMI", ylab="Counts",horizontal= TRUE)
```

```{r}
#Normality of BMI
shapiro.test(df$bmi)
```

```{r}
### Test normality based on Stroke group

data_no_stroke<- subset(df, stroke == 0)
shapiro.test(data_no_stroke$bmi)
```

```{r}
data_yes_stroke <- subset(df, stroke == 1)
shapiro.test(data_yes_stroke$bmi)
```

## Data changes for missing values in bmi
```{r}
median_bmi<- median(df$bmi,na.rm = TRUE)
df$bmi <- ifelse(is.na(df$bmi), median_bmi, df$bmi)
colSums(is.na(df))
```

No more missing values after that

## Remove id column from the dataset
```{r}
df <- subset(df, select = -c(id))
head(df)
```


# EDA
## Histogram of each variable
```{r}
library('ggplot2')

# Create a for loop to generate a histogram for each column
for (col in colnames(df)) {
  p <- ggplot(data = df) +
    geom_bar(mapping = aes(x = df[[col]])) +
    labs(title = col)
  print(p)
}
```

The dependent variable (DV), stroke, predominantly includes non-stroke patients. Among independent variables (IVs), BMI appears fairly normal but slightly right-skewed, while glucose levels are more significantly right-skewed. The age distribution spans 0-80 years and is relatively normal. For categorical IVs, the gender distribution is nearly balanced, with slightly more females. Most patients do not have hypertension or heart disease. The marital status shows a majority being ever married at about a 2:1 ratio. Employment is mostly private, and residence type is evenly split with a slight preference for urban areas. Smoking status reveals 'never smoked' as most common, with 'smokes' and 'former smoked' nearly equal; many records list smoking status as unknown.


## chi-square test for initial selection for categorical IVs
```{r}
#DV vs. categorical IVs
stroke_gender_tb <- table(df$stroke, df$gender)
stroke_hypertension_tb <- table(df$stroke, df$hypertension)
stroke_hd_tb <- table(df$stroke, df$heart_disease)
stroke_married_tb <- table(df$stroke, df$ever_married)
stroke_work_tb <- table(df$stroke, df$work_type)
stroke_Residence_tb <- table(df$stroke, df$Residence_type)
stroke_Smoking_tb <- table(df$stroke, df$smoking_status)
```

```{r}
chisq.test(stroke_gender_tb)
```

```{r}
chisq.test(stroke_hypertension_tb)
```

```{r}
chisq.test(stroke_hd_tb)
```

```{r}
chisq.test(stroke_married_tb)
```

```{r}
chisq.test(stroke_work_tb)
```

```{r}
chisq.test(stroke_Residence_tb)
```

```{r}
chisq.test(stroke_Smoking_tb)
```

## t-test or Mann-Whitney U test for initial selection for continuous IVs
```{r}
#Normality Assumption
groups <- split(df$bmi,df$stroke)
shapiro_results <- lapply(groups, shapiro.test)
p_values <- sapply(shapiro_results, function(x) x$p.value)
p_values
```

```{r}
#Mann-whiteny U test
mwu_result <- wilcox.test(df$bmi, df$stroke)
mwu_result
```

```{r}
#Normality Assumption
groups <- split(df$age,df$stroke)
shapiro_results <- lapply(groups, shapiro.test)
p_values <- sapply(shapiro_results, function(x) x$p.value)
p_values
```

```{r}
#Mann-whiteny U test
mwu_result <- wilcox.test(df$age, df$stroke)
mwu_result
```

```{r}
#Normality Assumption
groups <- split(df$avg_glucose_level,df$stroke)
shapiro_results <- lapply(groups, shapiro.test)
p_values <- sapply(shapiro_results, function(x) x$p.value)
p_values
```

```{r}
#Mann-whiteny U test
mwu_result <- wilcox.test(df$avg_glucose_level, df$stroke)
mwu_result
```
# Multicollinearity
Check for multicollinearity 

```{r}
library(car)
M <- lm(stroke~.,data=df) 
vif(M) 

```

# Interaction plots

From all the plots, smoking_status and bmi seem to have the strongest interaction

```{r}
interaction.plot(x.factor = df$stroke,
                 trace.factor = df$smoking_status,
                 response = df$bmi,
                 fun = median,
                 ylab = "bmi",
                 xlab = "stroke",
                 col = c("red", "orange",'green','blue','gray'),
                 trace.label = "smoking_status")
```


```{r}
interaction.plot(x.factor = df$stroke,
                 trace.factor = df$work_type,
                 response = df$bmi,
                 fun = median,
                 ylab = "bmi",
                 xlab = "stroke",
                 col = c("red", "orange",'green','blue','gray'),
                 trace.label = "work_type")
```

```{r}
interaction.plot(x.factor = df$stroke,
                 trace.factor = df$work_type,
                 response = df$avg_glucose_level,
                 fun = median,
                 ylab = "avg_glucose_level",
                 xlab = "stroke",
                 col = c("red", "orange",'green','blue','gray'),
                 trace.label = "work_type")
```

```{r}
interaction.plot(x.factor = df$stroke,
                 trace.factor = df$smoking_status,
                 response = df$age,
                 fun = median,
                 ylab = "age",
                 xlab = "stroke",
                 col = c("red", "orange",'green','blue','gray'),
                 trace.label = "smoking_status")
```


```{r}
interaction.plot(x.factor = df$stroke,
                 trace.factor = df$work_type,
                 response = df$age,
                 fun = median,
                 ylab = "age",
                 xlab = "stroke",
                 col = c("red", "orange",'green','blue','gray'),
                 trace.label = "work_type")
```

# Train-Test split

```{r}
library(caret)
library(rlang)
set.seed(123)  # Set a seed for reproducibility
split <- createDataPartition(df$stroke, p = 0.8, list = FALSE)  # Create the train-test split
train <- df[split, ]  # Training data
test <- df[-split, ]  # Testing data
```

```{r}
dim(train)
dim(test)
```

# Models and variables selection
## Forward Selection
```{r}
library(MASS) 
# Fit the full model  
full.model <- lm(stroke~., data = df) 
# Stepwise regression model 
step.model <- step(full.model, direction = "forward", trace = 0) 
summary(step.model) 

```

From the full model, age, hypertension, heart_disease, ever_married, avg_glucose_level would have an effect. Gender and bmi don't seem to have an impact. 


#### gender
```{r}
model <- glm(factor(stroke) ~ factor(gender) , data = train, family = "binomial")
summary(model)
```

gender is NOT significant

#### age
```{r}
model <- glm(factor(stroke) ~ age , data = train, family = "binomial")
summary(model)
```

age is significant

#### hypertension
```{r}
model <- glm(factor(stroke) ~ factor(hypertension) , data = train, family = "binomial")
summary(model)
```

hypertension is significant

#### age + hypertension
```{r}
model <- glm(factor(stroke) ~ age + factor(hypertension) , data = train, family = "binomial")
summary(model)
```

Age + Hypertension (AIC: 1263.5) < Age (AIC: 1273.3) \
Age + Hypertension (AIC: 1263.5) < Hypertension (AIC: 1499.3)

```{r}
pchisq(1269.3-1257.5,4086-4085,lower.tail = FALSE)
```

```{r}
pchisq(1495.3-1257.5,4086-4085,lower.tail = FALSE)
```

We move on with the full model

#### age + hypertension + heart_disease
```{r}
model <- glm(factor(stroke) ~ age + factor(hypertension)+factor(heart_disease) , data = train, family = "binomial")
summary(model)
```

Age + Hypertension + heart_disease (AIC: 1261.7) < Age + Hypertension (AIC: 1263.5)

```{r}
pchisq(1257.5-1253.7,4085-4084,lower.tail = FALSE)
```

We move on with the reduced model

#### age + hypertension + ever_married
```{r}
model <- glm(factor(stroke) ~ age + factor(hypertension)+ factor(ever_married) , data = train, family = "binomial")
summary(model)
```

ever_married is NOT significant

#### age + hypertension + work_type
```{r}
model <- glm(factor(stroke) ~ age + factor(hypertension)+factor(work_type) , data = train, family = "binomial")
summary(model)
```

Age + Hypertension + work_type (AIC: 1262.8) < Age + Hypertension (AIC: 1263.5)

```{r}
pchisq(1257.5-1248.8,4085-4081,lower.tail = FALSE)
```
We move on with the reduced model

#### age + hypertension + avg_glucose_level
```{r}
model <- glm(factor(stroke) ~ age + factor(hypertension) + avg_glucose_level , data = train, family = "binomial")
summary(model)
```

Age + Hypertension + avg_glucose_level (AIC: 1253) < Age + Hypertension (AIC: 1263.5)

```{r}
pchisq(1257.5-1245.0,4085-4084,lower.tail = FALSE)
```
We move on with the full model

#### age + hypertension + avg_glucose_level + bmi
```{r}
model <- glm(factor(stroke) ~ age + factor(hypertension) + avg_glucose_level + bmi , data = train, family = "binomial")
summary(model)
```

bmi is NOT significant

#### age + hypertension + avg_glucose_level + smoking_status
```{r}
model <- glm(factor(stroke) ~ age + factor(hypertension) + avg_glucose_level + factor(smoking_status) , data = train, family = "binomial")
summary(model)
```

Smoking status is NOT significant


### Comparing models with interaction

#### age + hypertension + avg_glucose_level
```{r}
model <- glm(factor(stroke) ~ age + factor(hypertension) + avg_glucose_level , data = train, family = "binomial")
summary(model)
```

#### age + hypertension + avg_glucose_level + interaction

All interactions: 

* factor(smoking_status):bmi
* factor(work_type):bmi
* factor(work_type):avg_glucose_level
* factor(smoking_status):age
* factor(work_type):age

```{r}
model_I <- glm(factor(stroke) ~ age + factor(hypertension) + avg_glucose_level + factor(smoking_status):bmi, data = train, family = "binomial")
summary(model_I)
```

The interaction is NOT significant \

Age + Hypertension + avg_glucose_level (AIC: 1253) < age + hypertension + avg_glucose_level + interaction (AIC: 1258.6)

```{r}
pchisq(1245-1242.6,4084-4080,lower.tail = FALSE)
```

Reduced model is better: age + hypertension + avg_glucose_level


### Classification Report

```{r}
table(df$stroke)
```

```{r}
#probability of stroke = class 1
249 / (4861 + 249)
```

```{r}
model <- glm(stroke ~ age + hypertension + avg_glucose_level, data = train, family = binomial)
pred <- predict(model, newdata = test, type = "response")
pred_class <- ifelse(pred > 0.04872798, 1, 0)
classification_table <- table(actual = test$stroke, predicted = pred_class)
classification_table
```

```{r}
TP <- classification_table[2,2]
FP <- classification_table[1,2]
TN <- classification_table[1,1]
FN <- classification_table[2,1]

sensitivity <- TP / (TP + FN)
specificity <- TN / (TN + FP)
accuracy <- (TP + TN)/ (TP + FN + TN + FP)

c(sensitivity,specificity,accuracy)
```

### ROC Curve

```{r}
#Without interaction

library(pROC)
test_roc <- roc(test$stroke ~ pred, plot = TRUE, print.auc = TRUE)
spec_rev <- rev(1 - test_roc$specificities)

# Plot the ROC curve with 1 - specificity on the x-axis
plot(1 - spec_rev, test_roc$sensitivities, type = "l", xlab = "1 - Specificity", ylab = "Sensitivity")
abline(a = 0, b = 1, lty = 2)
```

```{r}
#With interaction
pred <- predict(model_I, newdata = test, type = "response")
test_roc <- roc(test$stroke ~ pred, plot = TRUE, print.auc = TRUE)
spec_rev <- rev(1 - test_roc$specificities)

# Plot the ROC curve with 1 - specificity on the x-axis
plot(1 - spec_rev, test_roc$sensitivities, type = "l", xlab = "1 - Specificity", ylab = "Sensitivity")
abline(a = 0, b = 1, lty = 2)
```
